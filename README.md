
# ğŸ–ï¸ Palm Astro Project â€” Palm Image Segmentation using U-Net  

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![PyTorch](https://img.shields.io/badge/Framework-PyTorch-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![Status](https://img.shields.io/badge/Status-Completed-success.svg)

---

## ğŸ“˜ Overview
This project performs **palm image segmentation** using a **U-Net deep learning model** built in **PyTorch**.  
The model takes a hand image and predicts the palm region mask â€” useful for:

- Palmistry analysis  
- Biometrics  
- Gesture recognition  
- Hand shape detection  

---

## ğŸ“‚ Project Structure


palm-astro-project/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ images/ # input palm images (train/val)
â”‚ â”œâ”€â”€ masks/ # segmentation masks
â”œâ”€â”€ models/ # trained model weights (.pth)
â”œâ”€â”€ output/ # prediction outputs
â”œâ”€â”€ utils/ # helper scripts
â”œâ”€â”€ train.py # training script
â”œâ”€â”€ inference.py # inference and visualization
â”œâ”€â”€ make_masks.py # generate masks if missing
â”œâ”€â”€ make_small_dataset.py # create 200-image dataset
â”œâ”€â”€ requirements.txt # python dependencies
â””â”€â”€ README.md

## ğŸ§  Model Details
- **Architecture:** U-Net  
- **Encoder:** EfficientNet-B0 (ImageNet pretrained)  
- **Loss Function:** Binary Cross Entropy  
- **Optimizer:** Adam  
- **Epochs Trained:** 10  
- **Batch Size:** 2  
- **Framework:** PyTorch + segmentation-models-pytorch  

---

## ğŸ“¦ Dataset
Dataset used: **Human Palm Images** (from Kaggle)  
Download manually OR via CLI:



kaggle datasets download -d feyiamujo/human-palm-images


Unzip:



unzip human-palm-images.zip -d data/images


To create a smaller 200-image dataset:



python make_small_dataset.py


---

## âš™ï¸ Installation



git clone https://github.com/ishagahlot28/palm-astro-project.git

cd palm-astro-project
python -m venv venv
venv\Scripts\activate
pip install -r requirements.txt


---

## ğŸš€ Training



python train.py --data_dir data --split small_train --epochs 10 --batch_size 2 --save_dir models


Model will be saved in:



models/best_model.pth


---

## ğŸ§ª Inference



python inference.py


This will generate visualization similar to:

### Input vs Predicted Output
| Input Palm Image | Predicted Palm Region |
|------------------|----------------------|
| *(your input image)* | *(U-Net segmented palm mask)* |

---

## ğŸ“Š Sample Training Log



Epoch 1 - Avg Loss: 0.6389
Epoch 5 - Avg Loss: 0.1296
Epoch 10 - Avg Loss: 0.0390
Training complete â€” model saved to models/


---

## ğŸ“ Outputs
- âœ” `best_model.pth` â€” final model  
- âœ” `checkpoint_epoch_*.pth` â€” intermediate  
- âœ” `output/` â€” visual segmentation results  

---

## ğŸ§° Tech Stack

- Python 3.10+  
- PyTorch  
- segmentation-models-pytorch  
- NumPy  
- Pillow  
- OpenCV  
- Matplotlib  
- TQDM  



---

## âœ¨ Author
**Isha Gahlot**  
ğŸ”— GitHub: https://github.com/ishagahlot28  
ğŸ“… November 2025  